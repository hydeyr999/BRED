preprocess_strategy: light

model:
    backbone_path: "../../../aigtdpaper25/model/Mistral-7B-v0.1"
    lora_path: './weights/cross-model/mistral_gpt3_5_ep4_512_n2000/best'
#    lora_path: './weights/cross-model/mistral_gpt3_5_ep4_512_n500/last'
    max_length: 512 #1296
    num_labels: 1
    tokenizer:
        padding_side: left
        truncation_side: left
        use_fast: true

predict_params:
    per_device_eval_batch_size: 1